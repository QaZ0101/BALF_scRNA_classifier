{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### GAT MILD VS. SEVERE \n",
    "### load data (all csv)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from torch_geometric.explain import Explainer, GNNExplainer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get features to retain\n",
    "X_train = pd.read_csv('mild_vs_severe_training_data.csv')\n",
    "y_train = pd.read_csv('mild_vs_severe_training_label.csv')\n",
    "y_train = np.array(y_train.drop(columns=['Unnamed: 0']))\n",
    "X_train = np.array(X_train.drop(columns=['Unnamed: 0']))\n",
    "\n",
    "X_test = pd.read_csv('mild_vs_severe_test_data.csv')\n",
    "y_test = pd.read_csv('mild_vs_severe_test_label.csv')\n",
    "y_test = np.array(y_test.drop(columns=['Unnamed: 0']))\n",
    "X_test = np.array(X_test.drop(columns=['Unnamed: 0']))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate the adjacency matrix (correlation matrix) for training data.\n",
    "data_matrix = X_train\n",
    "\n",
    "# correlation threshold: only variable pairs with correlation coefficients greater than 0.8 are considered highly correlated.\n",
    "threshold = 0.8  \n",
    "\n",
    "if isinstance(data_matrix, pd.DataFrame):\n",
    "    data_matrix = data_matrix.to_numpy()\n",
    "\n",
    "correlation_matrix = np.corrcoef(data_matrix)\n",
    "adj_matrix = (np.abs(correlation_matrix) >= threshold).astype(int)\n",
    "\n",
    "labels = [True if i == ['Severe'] else False for i in y_train]\n",
    "\n",
    "# Convert adjacency matrix and node feature matrix to PyTorch Tensors\n",
    "adj_matrix = torch.tensor(adj_matrix, dtype=torch.long)\n",
    "feature_matrix = torch.tensor(data_matrix, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Build edge index\n",
    "edge_index = adj_matrix.nonzero(as_tuple=True)\n",
    "edge_index = torch.stack(edge_index, dim=0)\n",
    "\n",
    "# Create PyTorch Geometric Data object\n",
    "data_train = Data(x=feature_matrix, edge_index=edge_index, y=labels)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(adj_matrix.shape)\n",
    "print(data_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate the adjacency matrix (correlation matrix) for testing data.\n",
    "data_matrix = X_test \n",
    "threshold = 0.8\n",
    "\n",
    "if isinstance(data_matrix, pd.DataFrame):\n",
    "    data_matrix = data_matrix.to_numpy()\n",
    "\n",
    "correlation_matrix = np.corrcoef(data_matrix)\n",
    "adj_matrix = (np.abs(correlation_matrix) >= threshold).astype(int)\n",
    "\n",
    "labels = [True if i == ['Severe'] else False for i in y_test]\n",
    "\n",
    "# Convert adjacency matrix and node feature matrix to PyTorch Tensors\n",
    "adj_matrix = torch.tensor(adj_matrix, dtype=torch.long)\n",
    "feature_matrix = torch.tensor(data_matrix, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "# Build edge index\n",
    "edge_index = adj_matrix.nonzero(as_tuple=True)\n",
    "edge_index = torch.stack(edge_index, dim=0)\n",
    "\n",
    "# Create PyTorch Geometric Data object\n",
    "data_test = Data(x=feature_matrix, edge_index=edge_index, y=labels)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(adj_matrix.shape)\n",
    "print(data_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class GATClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, num_heads):\n",
    "        super(GATClassifier, self).__init__()\n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=num_heads, concat=True, dropout=0.6)\n",
    "        self.gat2 = GATConv(hidden_dim * num_heads, num_classes, heads=num_heads, concat=True, dropout=0.6)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x, edge_index = data.x, data.edge_index\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return torch.softmax(x, dim=1)\n",
    "\n",
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct = float(pred.eq(data.y).sum().item())\n",
    "        accuracy = correct / len(data.y)\n",
    "        return accuracy\n",
    "\n",
    "input_dim = feature_matrix.shape[1]\n",
    "hidden_dim = 64\n",
    "num_classes = len(set(labels.tolist()))\n",
    "num_heads = 4\n",
    "\n",
    "model = GATClassifier(input_dim, hidden_dim, num_classes, num_heads)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data_train.x, data_train.edge_index)\n",
    "    loss = criterion(out, data_train.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Evaluate the model on the train and test set\n",
    "    train_acc = evaluate(model, data_train)\n",
    "    test_acc = evaluate(model, data_test)\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {loss.item()}, Test Accuracy: {test_acc}\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# F1 score\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(data_test.x, data_test.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    pred = pred.tolist()\n",
    "    y_test = data_test.y.tolist()\n",
    "    f1 = f1_score(y_test, pred, average='weighted')\n",
    "    print(\"f1:\", f1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm_df = pd.DataFrame(cm, columns=['Predicted Positive', 'Predicted Negative'], index=['Actual Positive', 'Actual Negative'])\n",
    "\n",
    "print(cm_df)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# AUC-ROC\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def evaluate_f1(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        pred = out.argmax(dim=1)\n",
    "        f1 = f1_score(data.y.numpy(), pred.numpy(), average='macro')\n",
    "    return f1\n",
    "\n",
    "learning_rates = [0.003, 0.004, 0.005, 0.006, 0.007]\n",
    "weight_decays = [3e-4, 4e-4, 5e-4, 6e-4, 7e-4]\n",
    "\n",
    "results = np.zeros((len(learning_rates), len(weight_decays)))\n",
    "\n",
    "for i, lr in enumerate(learning_rates):\n",
    "    for j, wd in enumerate(weight_decays):\n",
    "        model = GATClassifier(input_dim, hidden_dim, num_classes, num_heads)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "        # Train the model\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data_train.x, data_train.edge_index)\n",
    "            loss = criterion(out, data_train.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model on test data\n",
    "        test_f1 = evaluate_f1(model, data_test)\n",
    "        results[i, j] = test_f1\n",
    "\n",
    "\n",
    "x_tick_labels = [f\"{wd:.4f}\" for wd in weight_decays]\n",
    "y_tick_labels = [f\"{lr:.4f}\" for lr in learning_rates]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(results, annot=True, fmt=\".2f\", xticklabels=x_tick_labels, yticklabels=y_tick_labels, ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Weight Decay\")\n",
    "ax.set_ylabel(\"Learning Rate\")\n",
    "ax.set_title(\"Test F1 Heatmap\")\n",
    "\n",
    "\n",
    "ax.set_xticks(np.arange(len(weight_decays)) + 0.5)\n",
    "ax.set_yticks(np.arange(len(learning_rates)) + 0.5)\n",
    "\n",
    "ax.set_xticklabels(x_tick_labels)\n",
    "ax.set_yticklabels(y_tick_labels)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha='right', rotation_mode='anchor')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GNNExplainer\n",
    "\n",
    "from torch_geometric.explain import Explainer, GNNExplainer\n",
    "\n",
    "explainer = Explainer(\n",
    "    model=model,\n",
    "    algorithm=GNNExplainer(epochs=200),\n",
    "    explanation_type='model',\n",
    "    node_mask_type='attributes',\n",
    "    edge_mask_type='object',\n",
    "    model_config=dict(\n",
    "        mode='multiclass_classification',\n",
    "        task_level='node',\n",
    "        return_type='probs',\n",
    "    ),\n",
    ")\n",
    "\n",
    "node_index = 0\n",
    "explanation = explainer(data_test.x, data_test.edge_index, index=node_index)\n",
    "print(f'Generated explanations in {explanation.available_explanations}')\n",
    "\n",
    "path = 'feature_importance_mildVSsevere.png'\n",
    "explanation.visualize_feature_importance(path, top_k=15)\n",
    "print(f\"Feature importance plot has been saved to '{path}'\")\n",
    "\n",
    "# path = 'subgraph_v1.pdf'\n",
    "# explanation.visualize_graph(path)\n",
    "# print(f\"Subgraph visualization plot has been saved to '{path}'\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in [1012, 793, 728, 1140, 216, 1664, 1073, 212, 1222, 658]:\n",
    "    i = i + 1\n",
    "    print(X_train.columns[i])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}